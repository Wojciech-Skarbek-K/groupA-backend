{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>AI001 - Find Suitable Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from datasets import load_dataset\n",
    "help(load_dataset)\n",
    "\n",
    "mode = 'force_redownload'\n",
    "\n",
    "train_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'train', download_mode = mode)\n",
    "test_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'test', download_mode = mode)\n",
    "val_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'validation', download_mode = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 23897\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 2938\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 2984\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "val_data = pd.DataFrame(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage data that is TRAIN: 80.14\n",
      "percentage data that is TEST: 9.85\n",
      "percentage data that is VALIDATION: 10.01\n"
     ]
    }
   ],
   "source": [
    "total_nrows = len(train_data) + len(test_data) + len(val_data)\n",
    "print('percentage data that is TRAIN:', round((len(train_data)/total_nrows)*100, 2))\n",
    "print('percentage data that is TEST:', round((len(test_data)/total_nrows)*100, 2))\n",
    "print('percentage data that is VALIDATION:', round((len(val_data)/total_nrows)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legacy code for loading data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data source: https://huggingface.co/datasets/md_gender_bias\n",
    "train_data = pd.read_json('md_gender_bias/funpedia/train.jsonl', lines = True)\n",
    "test_data = pd.read_json('md_gender_bias/funpedia/test.jsonl', lines = True)\n",
    "val_data = pd.read_json('md_gender_bias/funpedia/valid.jsonl', lines = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

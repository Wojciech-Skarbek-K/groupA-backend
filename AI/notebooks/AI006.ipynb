{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from datasets import load_dataset\n",
    "help(load_dataset)\n",
    "\n",
    "mode = 'force_redownload'\n",
    "\n",
    "train_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'train', download_mode = mode)\n",
    "test_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'test', download_mode = mode)\n",
    "val_data = load_dataset('md_gender_bias', name = 'funpedia', split = 'validation', download_mode = mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 23897\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 2938\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'gender', 'title', 'persona'],\n",
      "    num_rows: 2984\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "val_data = pd.DataFrame(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage data that is TRAIN: 80.14\n",
      "percentage data that is TEST: 9.85\n",
      "percentage data that is VALIDATION: 10.01\n"
     ]
    }
   ],
   "source": [
    "total_nrows = len(train_data) + len(test_data) + len(val_data)\n",
    "print('percentage data that is TRAIN:', round((len(train_data)/total_nrows)*100, 2))\n",
    "print('percentage data that is TEST:', round((len(test_data)/total_nrows)*100, 2))\n",
    "print('percentage data that is VALIDATION:', round((len(val_data)/total_nrows)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows raw unified dataset: 29819\n"
     ]
    }
   ],
   "source": [
    "#combine pre-split datasets into one then apply train test split function twice\n",
    "unified_data = train_data.append(test_data, ignore_index=True)\n",
    "unified_data = unified_data.append(val_data, ignore_index=True)\n",
    "print('nrows raw unified dataset:', len(unified_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns except text and label\n",
    "unified_data = unified_data[['text', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure all text lowercase so can compare for duplicates\n",
    "for col in ['text', 'gender']:\n",
    "    unified_data[col] = unified_data[col].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 1\n",
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "#check duplicate rows in 'text' column\n",
    "print('Number of duplicates:', len(unified_data[unified_data.duplicated(['text'])]))\n",
    "#drop duplicates\n",
    "unified_data.drop_duplicates(subset=['text'], inplace = True)\n",
    "#recheck number of duplicates\n",
    "print('Number of duplicates:', len(unified_data[unified_data.duplicated(['text'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NAs\n",
    "unified_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'gender-neutral' class?\n",
    "unified_data = unified_data[unified_data['gender'] != 'gender-neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsample 'male' to fix class imbalance\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority', random_state= 0)\n",
    "X = np.array(unified_data['text']).reshape(-1, 1)\n",
    "y = np.array(unified_data['gender']).reshape(-1, 1)\n",
    "X_undersample, y_undersample = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten to 1D array in order to reocmbine into a new undersampled 'unified_data' dataframe\n",
    "X_undersample = X_undersample.flatten()\n",
    "y_undersample = y_undersample.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8914,)\n",
      "(8914,)\n"
     ]
    }
   ],
   "source": [
    "print(X_undersample.shape)\n",
    "print(y_undersample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_data = pd.DataFrame({'text': X_undersample, 'gender': list(y_undersample)}, columns=['text', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>len_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>danielle frenkel is a high jumper born in israel</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tania mihailuk is a politician who was born in...</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>juliet taylor is a woman who works as a castin...</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>margaret caroline rudd was born in britain. sh...</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>retta scott was an american artist who died in...</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  gender  len_text\n",
       "0   danielle frenkel is a high jumper born in israel  female         0\n",
       "1  tania mihailuk is a politician who was born in...  female         0\n",
       "2  juliet taylor is a woman who works as a castin...  female         0\n",
       "3  margaret caroline rudd was born in britain. sh...  female         0\n",
       "4  retta scott was an american artist who died in...  female         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unified_data['len_text'] = 0\n",
    "\n",
    "unified_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inefficient loop takes too long\n",
    "#for row in range(0, len(unified_data)):\n",
    "    #unified_data['len_text'][row] = len(unified_data['text'][row])\n",
    "    \n",
    "unified_data['len_text'] = unified_data['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 'train_test_split'\n",
    "X = unified_data['text']\n",
    "y = unified_data['gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.2, stratify = y)   #'stratify' argument ensures same class proportions for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text gender  len_text  \\\n",
      "4457  holy moly! josh brown guest starred in the sho...   male        99   \n",
      "4458  jim colver has been serving the residents of a...   male        74   \n",
      "4459  born in cleveland, ford was luckily taken by t...   male       104   \n",
      "\n",
      "      gender_id  \n",
      "4457          0  \n",
      "4458          0  \n",
      "4459          0  \n",
      "                                                text  gender  len_text  \\\n",
      "0   danielle frenkel is a high jumper born in israel  female        48   \n",
      "1  tania mihailuk is a politician who was born in...  female        56   \n",
      "2  juliet taylor is a woman who works as a castin...  female        56   \n",
      "\n",
      "   gender_id  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n"
     ]
    }
   ],
   "source": [
    "#convert two classes to new binary id column\n",
    "unified_data['gender_id'] = unified_data['gender']\n",
    "unified_data['gender_id'].replace(['male', 'female'], [0, 1], inplace = True)\n",
    "print(unified_data[unified_data['gender'] == 'male'].head(3))\n",
    "print(unified_data[unified_data['gender'] == 'female'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_unified = unified_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>AI006 - Output Sentiment Analysis From Pretrained Model</font>\n",
    "\n",
    "- https://towardsdatascience.com/the-most-favorable-pre-trained-sentiment-classifiers-in-python-9107c06442c6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#calculate the negative, positive, neutral and compound scores, plus verbal evaluation\n",
    "def sentiment_vader(sentence):\n",
    "\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    negative = sentiment_dict['neg']\n",
    "    neutral = sentiment_dict['neu']\n",
    "    positive = sentiment_dict['pos']\n",
    "    compound = sentiment_dict['compound']\n",
    "\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        overall_sentiment = \"Positive\"\n",
    "\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        overall_sentiment = \"Negative\"\n",
    "\n",
    "    else :\n",
    "        overall_sentiment = \"Neutral\"\n",
    "    \n",
    "    print('negative, neutral, positive, compound, overall_sentiment')\n",
    "    return negative, neutral, positive, compound, overall_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: danielle frenkel is a high jumper born in israel --> \n",
      "SENTIMENT: (0.0, 1.0, 0.0, 0.0, 'Neutral') \n",
      " ------------------------------\n",
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: tania mihailuk is a politician who was born in australia --> \n",
      "SENTIMENT: (0.0, 1.0, 0.0, 0.0, 'Neutral') \n",
      " ------------------------------\n",
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: juliet taylor is a woman who works as a casting director --> \n",
      "SENTIMENT: (0.0, 1.0, 0.0, 0.0, 'Neutral') \n",
      " ------------------------------\n",
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: margaret caroline rudd was born in britain. she was a notorious female forger. --> \n",
      "SENTIMENT: (0.195, 0.805, 0.0, -0.4404, 'Negative') \n",
      " ------------------------------\n",
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: retta scott was an american artist who died in 1990 --> \n",
      "SENTIMENT: (0.286, 0.714, 0.0, -0.5574, 'Negative') \n",
      " ------------------------------\n",
      "negative, neutral, positive, compound, overall_sentiment\n",
      "TEXT: cicely mary barker was a fantasy illustrator who depicted fairies and flowers --> \n",
      "SENTIMENT: (0.0, 1.0, 0.0, 0.0, 'Neutral') \n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2 + 1):\n",
    "    print('TEXT:', other_unified['text'][i], '-->', '\\nSENTIMENT:', sentiment_vader(other_unified['text'][i]), '\\n', '-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "#call the classifier\n",
    "def sentiment_textblob(row):\n",
    "  \n",
    "    classifier = TextBlob(row)\n",
    "    polarity = classifier.sentiment.polarity\n",
    "    subjectivity = classifier.sentiment.subjectivity\n",
    "    \n",
    "    print('polarity, subjectivity')\n",
    "    return polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity, subjectivity\n",
      "TEXT: danielle frenkel is a high jumper born in israel --> \n",
      "SENTIMENT: (0.16, 0.5399999999999999) \n",
      " ------------------------------\n",
      "polarity, subjectivity\n",
      "TEXT: tania mihailuk is a politician who was born in australia --> \n",
      "SENTIMENT: (0.0, 0.0) \n",
      " ------------------------------\n",
      "polarity, subjectivity\n",
      "TEXT: juliet taylor is a woman who works as a casting director --> \n",
      "SENTIMENT: (0.0, 0.0) \n",
      " ------------------------------\n",
      "polarity, subjectivity\n",
      "TEXT: margaret caroline rudd was born in britain. she was a notorious female forger. --> \n",
      "SENTIMENT: (0.0, 0.16666666666666666) \n",
      " ------------------------------\n",
      "polarity, subjectivity\n",
      "TEXT: retta scott was an american artist who died in 1990 --> \n",
      "SENTIMENT: (0.0, 0.0) \n",
      " ------------------------------\n",
      "polarity, subjectivity\n",
      "TEXT: cicely mary barker was a fantasy illustrator who depicted fairies and flowers --> \n",
      "SENTIMENT: (0.0, 0.0) \n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2 + 1):\n",
    "    print('TEXT:', other_unified['text'][i], '-->', '\\nSENTIMENT:', sentiment_textblob(other_unified['text'][i]), '\\n', '-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Happy Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "install error, sentencepiece not ocmpatible with Python 3.10 seemingly\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #sentencepiece causing error 'legacy-install-failure': https://stackoverflow.com/questions/71575380/sentencepiece-library-is-not-being-installed-in-the-system\n",
    "    from happytransformer import HappyTextClassification\n",
    "\n",
    "    happy_tc = HappyTextClassification(model_type=\"DISTILBERT\", model_name=\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)\n",
    "\n",
    "    def sentiment_happy_transformer(text):\n",
    "        result = happy_tc.classify_text(text)\n",
    "        if result.label == 'LABEL_1':\n",
    "            print('positive sentiment:', result.score)\n",
    "        elif result.label == 'LABEL_0':\n",
    "            print('negative sentiment:', result.score)\n",
    "        else:\n",
    "            print('neutral sentiment:', result.score)\n",
    "            \n",
    "    for i in range(0, 2 + 1):\n",
    "        sentiment_happy_transformer(other_unified['text'][i])\n",
    "        \n",
    "except:\n",
    "    print('install error, sentencepiece not ocmpatible with Python 3.10 seemingly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://dev.classmethod.jp/articles/comprehend-operations-using-python-boto3/\n",
    "\n",
    "import boto3\n",
    "\n",
    "def detect_sentiment(text):\n",
    "    comprehend = boto3.client('comprehend', region_name='eu-west-2')\n",
    "    response = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: danielle frenkel is a high jumper born in israel --> \n",
      "ANALYSIS:\n",
      " {'Sentiment': 'NEUTRAL', 'SentimentScore': {'Positive': 0.07776756584644318, 'Negative': 0.017122093588113785, 'Neutral': 0.9037699103355408, 'Mixed': 0.0013403829652816057}, 'ResponseMetadata': {'RequestId': '4c755e42-a77a-4283-9b23-03e1fe7cf4ef', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '4c755e42-a77a-4283-9b23-03e1fe7cf4ef', 'content-type': 'application/x-amz-json-1.1', 'content-length': '164', 'date': 'Mon, 18 Jul 2022 12:14:44 GMT'}, 'RetryAttempts': 0}} \n",
      " ------------------------------\n",
      "TEXT: tania mihailuk is a politician who was born in australia --> \n",
      "ANALYSIS:\n",
      " {'Sentiment': 'NEUTRAL', 'SentimentScore': {'Positive': 0.0014963001012802124, 'Negative': 0.042056210339069366, 'Neutral': 0.9535102248191833, 'Mixed': 0.0029372223652899265}, 'ResponseMetadata': {'RequestId': '0777f138-1083-46b1-8f42-38622f802744', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '0777f138-1083-46b1-8f42-38622f802744', 'content-type': 'application/x-amz-json-1.1', 'content-length': '166', 'date': 'Mon, 18 Jul 2022 12:14:45 GMT'}, 'RetryAttempts': 0}} \n",
      " ------------------------------\n",
      "TEXT: juliet taylor is a woman who works as a casting director --> \n",
      "ANALYSIS:\n",
      " {'Sentiment': 'NEUTRAL', 'SentimentScore': {'Positive': 0.08453038334846497, 'Negative': 0.0200099628418684, 'Neutral': 0.8621273040771484, 'Mixed': 0.03333231434226036}, 'ResponseMetadata': {'RequestId': '7f908587-deeb-43be-b91d-1b6d03e9f1db', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '7f908587-deeb-43be-b91d-1b6d03e9f1db', 'content-type': 'application/x-amz-json-1.1', 'content-length': '160', 'date': 'Mon, 18 Jul 2022 12:14:45 GMT'}, 'RetryAttempts': 0}} \n",
      " ------------------------------\n",
      "TEXT: margaret caroline rudd was born in britain. she was a notorious female forger. --> \n",
      "ANALYSIS:\n",
      " {'Sentiment': 'NEUTRAL', 'SentimentScore': {'Positive': 0.0181853249669075, 'Negative': 0.018061431124806404, 'Neutral': 0.8992886543273926, 'Mixed': 0.06446446478366852}, 'ResponseMetadata': {'RequestId': 'cd56f9c7-4c97-47b5-a271-a46bdcddd6b2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'cd56f9c7-4c97-47b5-a271-a46bdcddd6b2', 'content-type': 'application/x-amz-json-1.1', 'content-length': '161', 'date': 'Mon, 18 Jul 2022 12:14:45 GMT'}, 'RetryAttempts': 0}} \n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2 + 1):\n",
    "    print('TEXT:', other_unified['text'][i], '-->', '\\nANALYSIS:\\n', detect_sentiment(other_unified['text'][i]), '\\n', '-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### text2emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT: danielle frenkel is a high jumper born in israel --> \n",
      "EMOTIONS: {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.0, 'Sad': 0.5, 'Fear': 0.5} \n",
      " ------------------------------\n",
      "TEXT: tania mihailuk is a politician who was born in australia --> \n",
      "EMOTIONS: {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.0, 'Sad': 1.0, 'Fear': 0.0} \n",
      " ------------------------------\n",
      "TEXT: juliet taylor is a woman who works as a casting director --> \n",
      "EMOTIONS: {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.5, 'Sad': 0.0, 'Fear': 0.5} \n",
      " ------------------------------\n",
      "TEXT: margaret caroline rudd was born in britain. she was a notorious female forger. --> \n",
      "EMOTIONS: {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.0, 'Sad': 1.0, 'Fear': 0.0} \n",
      " ------------------------------\n",
      "TEXT: retta scott was an american artist who died in 1990 --> \n",
      "EMOTIONS: {'Happy': 0.0, 'Angry': 0.0, 'Surprise': 0.0, 'Sad': 0.0, 'Fear': 1.0} \n",
      " ------------------------------\n",
      "TEXT: cicely mary barker was a fantasy illustrator who depicted fairies and flowers --> \n",
      "EMOTIONS: {'Happy': 0, 'Angry': 0, 'Surprise': 0, 'Sad': 0, 'Fear': 0} \n",
      " ------------------------------\n"
     ]
    }
   ],
   "source": [
    "#be aware, text2emotion builds on top of NLTK and so requires NLTK data downloads to work - recurring SSL CERTIFICATE VERIFY FAILED error\n",
    "#I downloaded manually and stored in relevant directory\n",
    "import text2emotion as te\n",
    "\n",
    "for i in range(0, 2 + 1):\n",
    "        print('TEXT:', other_unified['text'][i], '-->', '\\nEMOTIONS:', te.get_emotion(other_unified['text'][i]), '\\n', '-'*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
